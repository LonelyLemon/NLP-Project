{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HUGabwvm1jn",
        "outputId": "36b79365-3892-40c4-afa5-825a08142896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing VLSP_Qwen_LoRA_Medical_Summarization.ipynb\n"
          ]
        }
      ],
      "source": [
        "%%writefile VLSP_Qwen_LoRA_Medical_Summarization.ipynb\n",
        "{\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"# VLSP Qwen LoRA Notebook\\n\",\n",
        "        \"# Fine-tuning Qwen với LoRA trên tập public_test.vi.txt (Medical Vietnamese)\\n\",\n",
        "        \"# Tác giả: Hoàng Minh\\n\",\n",
        "        \"# Mục tiêu: Tóm tắt văn bản y khoa tiếng Việt bằng Qwen + LoRA (PEFT)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 0. Cài đặt các thư viện cần thiết (chạy 1 lần)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {\n",
        "        \"vscode\": {\n",
        "          \"languageId\": \"shellscript\"\n",
        "        }\n",
        "      },\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"!pip install --upgrade pip\\n\",\n",
        "        \"!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\\n\",\n",
        "        \"!pip install transformers accelerate peft datasets sentencepiece sacrebleu python-pptx sentence-transformers nltk\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 1. Import các thư viện\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"import os\\n\",\n",
        "        \"import re\\n\",\n",
        "        \"import json\\n\",\n",
        "        \"import random\\n\",\n",
        "        \"import math\\n\",\n",
        "        \"import numpy as np\\n\",\n",
        "        \"import pandas as pd\\n\",\n",
        "        \"from pathlib import Path\\n\",\n",
        "        \"\\n\",\n",
        "        \"from datasets import Dataset\\n\",\n",
        "        \"import nltk\\n\",\n",
        "        \"from nltk.tokenize import sent_tokenize\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Transformers & PEFT\\n\",\n",
        "        \"from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\\n\",\n",
        "        \"from peft import LoraConfig, get_peft_model\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Evaluation\\n\",\n",
        "        \"import sacrebleu\\n\",\n",
        "        \"from sentence_transformers import SentenceTransformer, util\\n\",\n",
        "        \"\\n\",\n",
        "        \"# PPTX\\n\",\n",
        "        \"from pptx import Presentation\\n\",\n",
        "        \"from pptx.util import Inches, Pt\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 2. Cấu hình đường dẫn\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"DATA_PATH = Path('public_test.vi.txt')\\n\",\n",
        "        \"OUTPUT_DIR = Path('qwen_lora_output')\\n\",\n",
        "        \"OUTPUT_DIR.mkdir(exist_ok=True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"SEED = 42\\n\",\n",
        "        \"random.seed(SEED)\\n\",\n",
        "        \"np.random.seed(SEED)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 3. Đọc dữ liệu\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"text = DATA_PATH.read_text(encoding='utf-8')\\n\",\n",
        "        \"text = text.replace('\\\\r\\\\n', '\\\\n')\\n\",\n",
        "        \"records = [r.strip() for r in re.split(r\\\"\\\\n\\\\s*\\\\n\\\", text) if r.strip()]\\n\",\n",
        "        \"print(f\\\"Số văn bản gốc: {len(records)}\\\")\\n\",\n",
        "        \"records[:3]\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 4. Xem thử vài mẫu\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"for i, rec in enumerate(records[:5]):\\n\",\n",
        "        \"    print(f\\\"---- RECORD {i+1} ----\\\")\\n\",\n",
        "        \"    print(rec[:800])\\n\",\n",
        "        \"    print(\\\"\\\\n\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 5. Tạo pseudo-target (dùng câu đầu làm tóm tắt ngắn)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"nltk.download('punkt', quiet=True)\\n\",\n",
        "        \"\\n\",\n",
        "        \"examples = []\\n\",\n",
        "        \"for rec in records:\\n\",\n",
        "        \"    sents = sent_tokenize(rec, language='english')  # Vietnamese không có sẵn, dùng English tạm ổn\\n\",\n",
        "        \"    if len(sents) >= 2:\\n\",\n",
        "        \"        source = rec\\n\",\n",
        "        \"        target = sents[0].strip()\\n\",\n",
        "        \"        examples.append({'text': source, 'summary': target})\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"Số mẫu sau khi tạo pseudo-label: {len(examples)}\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 6. Tạo HuggingFace Dataset + chia train/val\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"ds = Dataset.from_list(examples)\\n\",\n",
        "        \"train_test = ds.train_test_split(test_size=0.1, seed=SEED)\\n\",\n",
        "        \"train_ds = train_test['train']\\n\",\n",
        "        \"eval_ds = train_test['test']\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(f\\\"Train: {len(train_ds)}, Eval: {len(eval_ds)}\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Lưu preview\\n\",\n",
        "        \"(OUTPUT_DIR / 'train_preview.json').write_text(json.dumps(train_ds[:5], ensure_ascii=False, indent=2), encoding='utf-8')\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 7. Load Qwen tokenizer & model (thay MODEL_NAME nếu cần)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"MODEL_NAME = os.getenv('QWEN_MODEL', 'Qwen/Qwen2.5-7B-Instruct')  # Thay bằng model bạn có quyền truy cập\\n\",\n",
        "        \"\\n\",\n",
        "        \"try:\\n\",\n",
        "        \"    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\\n\",\n",
        "        \"    print(f\\\"Loaded tokenizer: {MODEL_NAME}\\\")\\n\",\n",
        "        \"except Exception as e:\\n\",\n",
        "        \"    print(\\\"Không load được Qwen, fallback về gpt2 để test\\\")\\n\",\n",
        "        \"    tokenizer = AutoTokenizer.from_pretrained('gpt2')\\n\",\n",
        "        \"\\n\",\n",
        "        \"if tokenizer.pad_token is None:\\n\",\n",
        "        \"    tokenizer.pad_token = tokenizer.eos_token\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 8. Preprocessing\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"max_input_length = 1024\\n\",\n",
        "        \"max_target_length = 128\\n\",\n",
        "        \"\\n\",\n",
        "        \"def preprocess_function(examples):\\n\",\n",
        "        \"    inputs = [f\\\"<|im_start|>system\\\\nBạn là một trợ lý y khoa tiếng Việt.<|im_end|>\\\\n<|im_start|>user\\\\nTóm tắt đoạn văn y khoa sau bằng tiếng Việt:\\\\n{t}<|im_end|>\\\\n<|im_start|>assistant\\\\n\\\" for t in examples['text']]\\n\",\n",
        "        \"    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\\\"max_length\\\")\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    with tokenizer.as_target_tokenizer():\\n\",\n",
        "        \"        labels = tokenizer(examples['summary'], max_length=max_target_length, truncation=True, padding=\\\"max_length\\\")\\n\",\n",
        "        \"    \\n\",\n",
        "        \"    model_inputs[\\\"labels\\\"] = labels[\\\"input_ids\\\"]\\n\",\n",
        "        \"    return model_inputs\\n\",\n",
        "        \"\\n\",\n",
        "        \"train_tokenized = train_ds.map(preprocess_function, batched=True, remove_columns=['text','summary'])\\n\",\n",
        "        \"eval_tokenized = eval_ds.map(preprocess_function, batched=True, remove_columns=['text','summary'])\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 9. Load model + LoRA\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"try:\\n\",\n",
        "        \"    model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True, device_map=\\\"auto\\\")\\n\",\n",
        "        \"    model.resize_token_embeddings(len(tokenizer))\\n\",\n",
        "        \"except Exception as e:\\n\",\n",
        "        \"    print(\\\"Không load được model lớn, dùng gpt2 để demo\\\")\\n\",\n",
        "        \"    model = AutoModelForCausalLM.from_pretrained('gpt2')\\n\",\n",
        "        \"    model.resize_token_embeddings(len(tokenizer))\\n\",\n",
        "        \"\\n\",\n",
        "        \"# LoRA config\\n\",\n",
        "        \"peft_config = LoraConfig(\\n\",\n",
        "        \"    task_type=\\\"CAUSAL_LM\\\",\\n\",\n",
        "        \"    inference_mode=False,\\n\",\n",
        "        \"    r=8,\\n\",\n",
        "        \"    lora_alpha=32,\\n\",\n",
        "        \"    lora_dropout=0.1,\\n\",\n",
        "        \"    target_modules=[\\\"q_proj\\\", \\\"v_proj\\\"]\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"model = get_peft_model(model, peft_config)\\n\",\n",
        "        \"model.print_trainable_parameters()\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 10. Trainer\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"training_args = TrainingArguments(\\n\",\n",
        "        \"    output_dir=str(OUTPUT_DIR / \\\"checkpoint\\\"),\\n\",\n",
        "        \"    per_device_train_batch_size=2,\\n\",\n",
        "        \"    per_device_eval_batch_size=2,\\n\",\n",
        "        \"    num_train_epochs=3,\\n\",\n",
        "        \"    logging_steps=50,\\n\",\n",
        "        \"    evaluation_strategy=\\\"epoch\\\",\\n\",\n",
        "        \"    save_strategy=\\\"epoch\\\",\\n\",\n",
        "        \"    learning_rate=2e-5,\\n\",\n",
        "        \"    weight_decay=0.01,\\n\",\n",
        "        \"    fp16=False,\\n\",\n",
        "        \"    bf16=False,\\n\",\n",
        "        \"    push_to_hub=False,\\n\",\n",
        "        \"    save_total_limit=2,\\n\",\n",
        "        \"    report_to=[]  # tắt wandb nếu không cần\\n\",\n",
        "        \")\\n\",\n",
        "        \"\\n\",\n",
        "        \"trainer = Trainer(\\n\",\n",
        "        \"    model=model,\\n\",\n",
        "        \"    args=training_args,\\n\",\n",
        "        \"    train_dataset=train_tokenized,\\n\",\n",
        "        \"    eval_dataset=eval_tokenized,\\n\",\n",
        "        \"    tokenizer=tokenizer,\\n\",\n",
        "        \")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 11. Huấn luyện (bỏ comment để chạy)\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"# trainer.train()\\n\",\n",
        "        \"# trainer.save_model(OUTPUT_DIR / \\\"final_model\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## 12. Tạo báo cáo và slide\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"execution_count\": null,\n",
        "      \"metadata\": {},\n",
        "      \"outputs\": [],\n",
        "      \"source\": [\n",
        "        \"def write_report():\\n\",\n",
        "        \"    md = f\\\"\\\"\\\"# VLSP Medical Domain — Fine-tuning Qwen với LoRA\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Dữ liệu\\n\",\n",
        "        \"- Số mẫu train: {len(train_ds)}\\n\",\n",
        "        \"- Số mẫu eval: {len(eval_ds)}\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Model\\n\",\n",
        "        \"- Base model: {MODEL_NAME}\\n\",\n",
        "        \"- LoRA: r=8, alpha=32\\n\",\n",
        "        \"\\n\",\n",
        "        \"## Kết quả\\n\",\n",
        "        \"- Chưa chạy đánh giá (cần chạy trainer.train() trước)\\n\",\n",
        "        \"\\\"\\\"\\\"\\n\",\n",
        "        \"    (OUTPUT_DIR / \\\"report.md\\\").write_text(md, encoding=\\\"utf-8\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"def create_pptx():\\n\",\n",
        "        \"    prs = Presentation()\\n\",\n",
        "        \"    slide = prs.slides.add_slide(prs.slide_layouts[0])\\n\",\n",
        "        \"    slide.shapes.title.text = \\\"VLSP Medical — Fine-tuning Qwen với LoRA\\\"\\n\",\n",
        "        \"    slide.placeholders[1].text = \\\"Hoàng Minh\\\\nAuto-generated\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"    s = prs.slides.add_slide(prs.slide_layouts[1])\\n\",\n",
        "        \"    s.shapes.title.text = \\\"Tổng quan\\\"\\n\",\n",
        "        \"    s.shapes.placeholders[1].text_frame.text = f\\\"Train: {len(train_ds)} mẫu\\\\nEval: {len(eval_ds)} mẫu\\\\nModel: {MODEL_NAME}\\\"\\n\",\n",
        "        \"\\n\",\n",
        "        \"    prs.save(OUTPUT_DIR / \\\"slides.pptx\\\")\\n\",\n",
        "        \"\\n\",\n",
        "        \"write_report()\\n\",\n",
        "        \"create_pptx()\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"Đã tạo báo cáo và slide!\\\")\"\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"markdown\",\n",
        "      \"metadata\": {},\n",
        "      \"source\": [\n",
        "        \"## Hoàn tất!\\n\",\n",
        "        \"Notebook đã sẵn sàng để chạy trên Google Colab, Kaggle hoặc máy có GPU.\\n\",\n",
        "        \"Chúc bạn đạt điểm cao VLSP!\"\n",
        "      ]\n",
        "    }\n",
        "  ],\n",
        "  \"metadata\": {\n",
        "    \"kernelspec\": {\n",
        "      \"display_name\": \"Python 3\",\n",
        "      \"language\": \"python\",\n",
        "      \"name\": \"python3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\",\n",
        "      \"version\": \"3.10.12\"\n",
        "    }\n",
        "  },\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 2\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e31d546d",
        "outputId": "faf9b4f3-3892-4d59-e872-4f5b85911826"
      },
      "source": [
        "import os\n",
        "print(os.listdir('.'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'VLSP_Qwen_LoRA_Medical_Summarization.ipynb', 'sample_data']\n"
          ]
        }
      ]
    }
  ]
}